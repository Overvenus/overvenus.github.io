<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="description" content="">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="description" content="solving least square problem in matrix.">
<meta name="keywords" content="Matlab, least square, matrix, Normal equations, QR-Factorization, ">

 
<meta property="og:type" content="article"/>
<meta property="og:description" content="solving least square problem in matrix."/>
<meta property="og:title" content="最小二乘法的矩阵形式 &middot; Neil ">
<meta property="og:site_name" content="Neil"/>
<meta property="og:image" content="" />
<meta property="og:image:type" content="image/jpeg" />
<meta property="og:image:width" content="" />
<meta property="og:image:height" content="" />
<meta property="og:url" content="http://neilsh.me/2015/12/25/least-square-in-matrix/">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2015-12-25"/>
<meta property="article:modified_time" content="2015-12-25"/>


<meta property="article:tag" content="Matlab">
<meta property="article:tag" content="least square">
<meta property="article:tag" content="matrix">
<meta property="article:tag" content="Normal equations">
<meta property="article:tag" content="QR-Factorization">



        <link rel="icon" href="http://neilsh.me/assets/favicon.png" type="image/x-icon">
        
        <link rel="stylesheet" href="http://neilsh.me/css/slender-font.css">
        
        <link rel="stylesheet" href="http://neilsh.me/css/slender-base.css">
        <link rel="stylesheet" href="http://neilsh.me/css/slender-color-schemes.css">
        <link rel="stylesheet" href="http://neilsh.me/css/font-awesome-4.5.0.min.css">
        <link rel="stylesheet" href="http://neilsh.me/css/highlight-9.1.0-default.min.css">
        <title>
            
                最小二乘法的矩阵形式 &middot; Neil
            
        </title>
    </head>
    <body class="color-scheme-white">
        <div class="container">
            <header>
                
                <nav><ul>
                    
                        <li>
                            <a href="/">
                                <i class="fa fa-home fa-fw"></i> <br>
                                Home
                            </a>
                        </li>
                    
                        <li>
                            <a href="/about/">
                                <i class="fa fa-user fa-fw"></i> <br>
                                About
                            </a>
                        </li>
                    
                        <li>
                            <a href="/archive/">
                                <i class="fa fa-archive fa-fw"></i> <br>
                                Archive
                            </a>
                        </li>
                    
                        <li>
                            <a href="/tags/">
                                <i class="fa fa-tags fa-fw"></i> <br>
                                Tags
                            </a>
                        </li>
                    
                </ul></nav>
                
                
                    <h1 class="title">最小二乘法的矩阵形式</h1>
                    <aside>
                        <p>on <strong>Fri, Dec 25, 2015</strong></p>
                    </aside>
                
            </header>


<div id="toc">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#拟合曲线与最小二乘法:7da2dc83c8d8e9ad8c6717b64208ddaf">拟合曲线与最小二乘法</a></li>
<li><a href="#最小二乘矩阵形式:7da2dc83c8d8e9ad8c6717b64208ddaf">最小二乘矩阵形式</a></li>
<li><a href="#最小二乘矩阵算法:7da2dc83c8d8e9ad8c6717b64208ddaf">最小二乘矩阵算法</a>
<ul>
<li><a href="#normal-equations:7da2dc83c8d8e9ad8c6717b64208ddaf">Normal equations</a></li>
<li><a href="#qr-factorization:7da2dc83c8d8e9ad8c6717b64208ddaf">QR-Factorization</a></li>
</ul></li>
<li><a href="#参考文献:7da2dc83c8d8e9ad8c6717b64208ddaf">参考文献</a></li>
</ul></li>
</ul>
</nav>
</div>

<article class="article-content">
    

<h2 id="拟合曲线与最小二乘法:7da2dc83c8d8e9ad8c6717b64208ddaf">拟合曲线与最小二乘法</h2>

<p>曲线拟合指：已知 m 个数据点 $(x_i,y_i ),i=1,2,3⋯,m$ 其中 m 不全相同，寻求函数 $f(x; \beta_0, \beta_1, \dots, \beta_n)$ 的待定参数 $\beta_0, \beta_1, \dots, \beta_n$ 的一组取值，使得在这组取值之下，函数 $f(x; \beta_0, \beta_1, \dots,\beta_n)$ 与已知 m 个数据点整体上最为接近。</p>

<p>最小二乘曲线拟合方法：根据已知数据，首先构造出能够反映含有回归参数的回归方程 $f(x; \beta_i),i = 0, 1, 2, …, n$ :</p>

<p>$$
\begin{align}
\hat{y} &amp;= \beta_0 + \beta_1 x + \beta_2 x^2 + \dots + \beta_n x^n \\
y &amp;= \hat{y} + \delta
\end{align}
$$</p>

<p>$\delta$ 是残差，这是回归方程与真实值存在出入的原因[1]。</p>

<p>根据 m 个数据点 $(x_i, y_i),i=1,2,3⋯,m$ 可以定义一个代表偏离程度的函数:</p>

<p>$$
S(\beta_0, \beta_1, \dots, \beta_n) = \sum_{j = 1}^m [y_i - f(x; \beta_0, \beta_1, \dots,\beta_n)]^2 = \sum \delta
$$</p>

<p>当 $S(\beta_0, \beta_1, \dots,\beta_n)$ 取得最小值时，此时的 $\beta_0, \beta_1, \dots,\beta_n$ 即为回归方程的回归系数，也是最小二乘解。</p>

<!-- more -->

<h2 id="最小二乘矩阵形式:7da2dc83c8d8e9ad8c6717b64208ddaf">最小二乘矩阵形式</h2>

<p>多组测量数据 $(x_i,y_i),i=1,2,3⋯,m$ 可以构成两个行列式[2]：</p>

<p>$$ X=\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_m \end{bmatrix}, Y=\begin{bmatrix} y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_m \end{bmatrix} $$</p>

<p>将多组数据代入到回归方程 $f$ 后，可得：</p>

<p>$$
Y = \beta_0 + \beta_1 X + \beta_2 X^2 + \dots + \beta_n X^n + \Delta
$$</p>

<p>$$
\Delta = \begin{bmatrix}
\delta_1 \\ \delta_2 \\ \delta_3 \\ \vdots \\ \delta_m
\end{bmatrix} , \beta=\begin{bmatrix}
\beta_0 \\ \beta_1 \\ \vdots \\ \beta_n
\end{bmatrix}
$$</p>

<p>再将 X 的转化为范德蒙德行列式：</p>

<p>$$
V=\begin{bmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \dots &amp; x_1^{n} \\
1 &amp; x_2 &amp; x_2^2 &amp; \dots &amp; x_2^{n} \\
1 &amp; x_3 &amp; x_3^2 &amp; \dots &amp; x_3^{n} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp;\vdots \\
1 &amp; x_m &amp; x_m^2 &amp; \dots &amp; x_m^{n}
\end{bmatrix}
$$</p>

<p>综上，可得：
$$
V\beta \approx Y \Rightarrow \Delta = \hat{Y} - Y = V\beta - Y
$$</p>

<p>$\hat{Y}$ 为 $\hat{y_i}$构成的列向量。</p>

<p>因为 $\Delta$ 的范数: $\Vert \Delta \Vert = \left( \sum_{i = 1}^m \delta_i^2 \right)^\frac{1}2$，所以求最小二乘解即可转化为如何使 $\Delta$ 的范数最小。</p>

<p>$$
\Vert \Delta \Vert^2  = \sum{\delta_i^2}
                      = \begin{bmatrix}
                         \delta_1 \delta_2 \dots \delta_n
                        \end{bmatrix} \begin{bmatrix}\delta_1 \\
                                                     \delta_2 \\
                                                     \vdots \\
                                                     \delta_n
                                      \end{bmatrix}
                      = \delta^T \delta
$$</p>

<p>$$
\Vert \Delta \Vert^2 = \Vert Y - V\beta \Vert^2 = \left( Y - V\beta \right)^T\left( Y - V\beta \right)
$$</p>

<h2 id="最小二乘矩阵算法:7da2dc83c8d8e9ad8c6717b64208ddaf">最小二乘矩阵算法</h2>

<blockquote>
<p>Let the scalar $\alpha$ be defined by
$$\alpha = Y^T X$$
where Y is n × 1, X is n × 1, and both Y and X are functions of the vector z. Then
$$\frac{d(\alpha)}{d(z)} = X^T\frac{d(Y)}{d(z)}+Y^T\frac{d(X)}{d(z)}$$</p>
</blockquote>

<p>根据上面定理，可得：
$$
\frac{d\Delta}{d\beta} = \frac{d}{d\beta}\left(\left( Y - V\beta \right)^T\left( Y - V\beta \right)\right) = -2V^T\left(Y-V\beta\right)
$$</p>

<p>为使 $\Delta$ 最小，可使 $\frac{d\Delta}{d\beta} = 0 \Rightarrow -2V^T\left(Y-V\beta\right) = 0$。</p>

<p>目前常见的算法有三种：Normal equations，QR-Factorization 和 SVD。</p>

<!--
这三个算法应用在计算机中时，有几点需要注意：
 1. 计算机中，浮点数的精度有限，当数过小时，就成0.
 2. 
-->

<!--
TOOD: 
 0. 是否可逆，奇异矩阵
 1. 计算机精度问题
 2. 算法稳定问题
-->

<h3 id="normal-equations:7da2dc83c8d8e9ad8c6717b64208ddaf">Normal equations</h3>

<p>$$
\begin{align}
-2V^T\left(Y-V\beta\right) &amp;= 0\\
V^T V\beta &amp;= V^TY \\
\beta &amp;= \left(V^T V\right)^{-1}V^T Y
\end{align}
$$
这个算法的时间复杂度最小，计算 $\beta$ 速度最快。但是在计算机中，浮点数的精度有限，当某些矩阵中的数过小时，就算该矩阵是满秩的非奇异的，但在计算机中，该矩阵就是奇异矩阵。
这个问题在 Normal equations 尤为严重[2]。比如下面矩阵 D：
$$
\begin{align}
D &amp;= \begin{bmatrix}
1 &amp; 1 \\
0 &amp; \delta \\
\delta &amp; 0 \\
\end{bmatrix}, |\delta| = 1 \times \text{Minimum precision} \\
D^T D &amp;= \begin{bmatrix}
1+\delta^2 &amp; 1 \\
1 &amp; 1+\delta^2
\end{bmatrix}
\end{align}
$$
这个算法出现了 $\delta^2$，容易出现奇异矩阵，所以不稳定。</p>

<h3 id="qr-factorization:7da2dc83c8d8e9ad8c6717b64208ddaf">QR-Factorization</h3>

<p>QR-Factorization 要比 Normal equations 稳定。
这个算法先把 $V$ 进行 QR 分解[<a href="https://en.wikipedia.org/wiki/QR_decomposition#Using_for_solution_to_linear_inverse_problems">3</a>]: $QR = V$
$$
\begin{align}
V^T V \beta &amp;= V^T Y \\
(QR)^T Q R \beta &amp;= (Q R)^T Y \\
R^T Q^T Q R \beta &amp;= R^T Q^T Y \\
R^T R \beta &amp;= R^T Q^T Y \\
R\beta &amp;= Q^T Y \\
\beta &amp;= R^{-1} Q^T Y
\end{align}
$$
由于 R 是一个上三角矩阵，所以求解很方便。这个也是 Matlab 中<code>polyfit</code>合的算法[2]。</p>

<h2 id="参考文献:7da2dc83c8d8e9ad8c6717b64208ddaf">参考文献</h2>

<blockquote>
<p>[1] Chatterjee, Samprit, Ali S. Hadi, and Bertram Price. 2000. Regression analysis by example. New York: Wiley.</p>

<p>[2] Moler, Cleve B. Numerical Computing with MATLAB: Revised Reprint. Siam, 2008.</p>

<p>[3] Wikipedia contributors, &ldquo;QR decomposition,&rdquo; Wikipedia, The Free Encyclopedia, <a href="https://en.wikipedia.org/wiki/QR_decomposition#Using_for_solution_to_linear_inverse_problems">https://en.wikipedia.org/wiki/QR_decomposition#Using_for_solution_to_linear_inverse_problems</a> (accessed November 23, 2015).</p>
</blockquote>

<!-- Links -->

</article>
<div class="article-tags">
    
    <ul id="tags">
  
    <li><a href="tags/matlab">#Matlab</a></li>
  
</ul>

</div>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        
            
                
        showMathMenu: false,
        showMathMenuMSIE: false,
                
            
        menuSettings: {
            
          zoom: "Double-Click",
            
            
          renderer: "SVG"
            
        },
        
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']],
          displayMath: [['$$','$$'], ['\\[','\\]']],
          processEscapes: true,
          processEnvironments: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
          TeX: { equationNumbers: { autoNumber: "AMS" },
               extensions: ["AMSmath.js", "AMSsymbols.js"] }
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        
        
        
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>

    
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    


<div class="comment-content">

    
        

<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'overvenus';
    var disqus_identifier = 'http:\/\/neilsh.me\/2015\/12\/25\/least-square-in-matrix\/';
    var disqus_title = '最小二乘法的矩阵形式';
    var disqus_url = 'http:\/\/neilsh.me\/2015\/12\/25\/least-square-in-matrix\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    

</div>

        </div>
        <footer>
            <div>
    <p>
        
            Copyright 2015 <i class="fa fa-copyright fa-fw"></i> Neil Shen
        
         </br><i class="fa fa-creative-commons fa-fw"></i> BY-NC-SA
    </p>
</div>
        </footer>
        <script src="http://neilsh.me/js/highlight-9.1.0.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        

    
        <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-69367210-1', 'auto');
        ga('send', 'pageview');
        </script>
    




  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?9546ee4e5eb51908bb6d5c50d98b6048";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


    </body>
</html>
